{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Train Set====================\n",
      "We have: 12500 positive reviews.\n",
      "We have: 12500 negative reviews.\n",
      "====================Test Set====================\n",
      "We have: 12500 positive reviews.\n",
      "We have: 12500 negative reviews.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "train_path = \"aclImdb/train\"\n",
    "test_path = \"aclImdb/test\"\n",
    "\n",
    "print(\"====================Train Set====================\")\n",
    "print(f\"We have: {len(os.listdir(train_path+'/pos'))} positive reviews.\")\n",
    "print(f\"We have: {len(os.listdir(train_path+'/neg'))} negative reviews.\")\n",
    "\n",
    "print(\"====================Test Set====================\")\n",
    "print(f\"We have: {len(os.listdir(test_path+'/pos'))} positive reviews.\")\n",
    "print(f\"We have: {len(os.listdir(test_path+'/neg'))} negative reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "positive_files = os.listdir(\"aclImdb/train/pos\")\n",
    "negative_files = os.listdir(\"aclImdb/train/neg\")\n",
    "test_positive_files = os.listdir(\"aclImdb/test/pos\")\n",
    "test_negative_files = os.listdir(\"aclImdb/test/neg\")\n",
    "\n",
    "positive_reviews = []\n",
    "negative_reviews = []\n",
    "\n",
    "test_positive_reviews = []\n",
    "test_negative_reviews = []\n",
    "\n",
    "for pos_file in positive_files:\n",
    "    with open(\"aclImdb/train/pos/\" + pos_file, \"r\", encoding='UTF-8') as f:\n",
    "        txt = f.read().replace(\"<br />\", \" \")\n",
    "        positive_reviews.append(txt)\n",
    "        #positive_words.extend(extract_words_from_text(txt))\n",
    "for neg_file in negative_files:\n",
    "    with open(\"aclImdb/train/neg/\" + neg_file, \"r\", encoding='UTF-8') as f:\n",
    "        txt = f.read().replace(\"<br />\", \" \")\n",
    "        negative_reviews.append(txt)\n",
    "        #negative_words.extend(extract_words_from_text(txt))\n",
    "\n",
    "\n",
    "print(positive_reviews[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 6, 3, 1194, 190, 8, 2199, 31, 1, 168, 54, 12, 47, 74, 5407, 40, 412, 88, 127, 12, 6018, 55, 4335, 122, 7, 1, 5309, 5629, 496, 67, 5, 303, 11, 1995, 6, 78, 2135, 5, 519, 77, 6, 6018, 1, 5, 1864, 8643, 1, 5215, 1737, 32, 62, 61, 197, 141, 60, 3817, 1, 4, 1, 251, 800, 29, 2989, 67, 4, 1, 6540, 9, 676, 2, 60, 1737, 46, 9, 195, 1, 317, 7, 59, 3, 1645, 4336, 1159, 5, 5110, 192, 1, 412, 9, 1199, 31, 300, 3, 283, 375, 3067, 180, 126, 5, 25, 4, 135, 6018, 1645, 2080, 5, 300, 9, 536, 11, 96, 1335, 4, 55, 456, 98, 11, 300, 6, 244, 4537, 48, 3, 2287, 11, 8, 248]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocabulary = 10000\n",
    "tokenizer = Tokenizer(num_words = vocabulary)\n",
    "tokenizer.fit_on_texts(positive_reviews)\n",
    "\n",
    "sequences_train_x = tokenizer.texts_to_sequences(positive_reviews)\n",
    "#sequences_train_y = tokenizer.texts_to_sequences(negative_reviews)\n",
    "\n",
    "\n",
    "print(sequences_train_x[0])\n",
    "#positive_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 20)\n"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "\n",
    "word_num = 20\n",
    "x_train = preprocessing.sequence.pad_sequences(sequences_train_x,maxlen=word_num)\n",
    "\n",
    "y_train = [[1]*12500]\n",
    "\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9,  536,   11,   96, 1335,    4,   55,  456,   98,   11,  300,\n",
       "          6,  244, 4537,   48,    3, 2287,   11,    8,  248])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "embedding_dim = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, embedding_dim, input_length=word_num))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras import optimizers\\n\\nepochs = 50\\n\\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.0001),\\n             loss='binary_crossentropy',metrics=['acc'])\\nhistory = model.fit(x_train,y_train,epochs=epochs,\\n                   batch_size=32,validation_data=(x_valid,y_valid))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras import optimizers\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.0001),\n",
    "             loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train,y_train,epochs=epochs,\n",
    "                   batch_size=32,validation_data=(x_valid,y_valid))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow20]",
   "language": "python",
   "name": "conda-env-tensorflow20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
